# 5.1 存储层次

存数据里面的层次 价格容量速度都不一样

内存访问最小单元是8bit 一个字节；如果数据总线是32位，一次读写要32位，4字节；由于地址对齐，所以不能随便开始。

cpu l1缓存 l2缓存 内存  l1l2是由mmu进行控制 访存是由操作系统进行控制

操作系统内存管理的效果：希望各个进程中，重叠的内核部分，也有不干扰的各自内容。通过MMU和os实现这一点，进程内容可以在内存中，也可以在外存中。

完成抽象，保护，方便共享，更好的虚拟化。

os进行内存管理的办法：1.重定位 段地址加偏移 整块搬 2.分段 一段内容连续 3.分页 分成基本单位(一个字节的话，粒度太细，管理的时候十分麻烦) 4.进行虚拟内存的管理

# 5.2 地址生成

程序->相应物理地址 还是有一定的过程

物理地址空间 硬件支持的空间 逻辑地址 cpu运行的时候看到的地址

逻辑地址的生成：编译->汇编(还有一些字符串)->链接(全都是二进制)->链接(别的库里面的地址)->重定位(运行的时候 放到内存里面)

地址生成时机和限制：1.编译时 (如果我直到最后放的地址 那么编译的时候就可以写死地址 如果改变 就需要重新编译) 

2.加载时 编译时位置未知 加载的时候才知道绝对地址

3.执行时 执行到相应指令 才知道在什么地方 好处就是运行的时候可以挪

**说实话 2 3 两点理解不是很深 需要实验想一下？**

例子：

mov eax 0xfffa620e 通过mmu将其翻译成物理地址 cpu控制器将物理地址发给总线 然后存储单元进行相应

地址检查相关：逻辑地址，比如访问数据段的数据->数据段有一个段基址和段长度，先检查段长度是不是合法，合法直接通过基址进行转换。

# 5.3内存分配

连续内存分配：给进程分配一个不小于指定大小的连续的内存区域。

外碎片(分配之间的)和内碎片(估计不是很准确 512分出去只能用510)

动态分区分配：加载的时候，分一连续块出来，地址是连续的  **OS需要维护的数据结构：所有进程的已分配分区 和 空闲分区**

动态分区的分配策略：最先匹配(地址排 从前往后分配第一个合适的分区 释放时和相邻的空闲分区合并) 最佳匹配 (比它大 但是大的最小 空闲分区按空间大小从大往小排列 分配时找一个合适的分区 释放时合并地址相邻的)最差匹配(直接找最大的 空闲空间从大到小排序 释放时相邻合并 并且调整列表顺序) **这个代码不清楚  难道后两种不都是一种情况吗 列表大小按从大往小排 合并的时候需要重排？**

# 5.4 碎片整理

调整进程位置来减少和避免碎片。

**碎片整理(调整进程的位置 肯定不行 因为地址引用)？碎片紧凑(移动内存分区 合并外部碎片) 的区别是啥？**

碎片整理：分区对换 就是在一定状态下 内存中进程被换到外存 应该对换哪一个？

# 5.5 伙伴系统

整个可分配分区大小为2^u 只可能从中间分开 ，不可能以其他方式来切

空闲块按大小和起始地址组织成二维数组 分配的时候查看空闲块 不断进行二分

有分配和合并的条件

在linux unix里头都有这样的实现 用于内核中的存储分配

